{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf8\n",
    "from __future__ import unicode_literals, print_function\n",
    "\n",
    "import plac\n",
    "import random\n",
    "from pathlib import Path\n",
    "import spacy\n",
    "from spacy.util import minibatch, compounding\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.gold import GoldCorpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG = {'device': 1, 'cpu_count': 4}\n",
    "TESTS = False\n",
    "spacy.require_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip, json\n",
    "def load_entries(fn): # '../data/datasets/nerus.jsonl.gz'\n",
    "    entries = []\n",
    "    with gzip.open(fn, 'r') as f:\n",
    "        for line in tqdm(f):\n",
    "            entry = json.loads(line)\n",
    "            entries.append(entry)\n",
    "    return entries\n",
    "    #del entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "g=GoldCorpus('../../data/UD_Russian-SynTagRus/ru_syntagrus-ud-train.json', \n",
    "             '../../data/UD_Russian-SynTagRus/ru_syntagrus-ud-test.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "g.limit = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ADP___',\n",
       " 'NUM___',\n",
       " 'NOUN__Animacy=Inan|Case=Loc|Gender=Masc|Number=Sing',\n",
       " 'ADP___',\n",
       " 'PROPN__Animacy=Inan|Case=Loc|Gender=Fem|Number=Sing',\n",
       " 'VERB__Aspect=Perf|Gender=Fem|Mood=Ind|Number=Sing|Tense=Past|VerbForm=Fin|Voice=Mid',\n",
       " 'ADP___',\n",
       " 'NOUN__Animacy=Inan|Case=Acc|Gender=Masc|Number=Sing',\n",
       " 'ADJ__Case=Nom|Degree=Pos|Gender=Fem|Number=Sing',\n",
       " 'NOUN__Animacy=Inan|Case=Nom|Gender=Fem|Number=Sing',\n",
       " 'NOUN__Animacy=Inan|Case=Gen|Gender=Fem|Number=Plur',\n",
       " 'PUNCT___',\n",
       " 'ADJ__Case=Nom|Degree=Pos|Gender=Masc|Number=Sing',\n",
       " 'NOUN__Animacy=Inan|Case=Nom|Gender=Masc|Number=Sing',\n",
       " 'NOUN__Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing',\n",
       " 'ADP___',\n",
       " 'NOUN__Animacy=Inan|Case=Ins|Gender=Neut|Number=Sing',\n",
       " 'ADP___',\n",
       " 'NOUN__Animacy=Inan|Case=Loc|Gender=Neut|Number=Sing',\n",
       " 'NOUN__Animacy=Inan|Case=Gen|Gender=Neut|Number=Plur',\n",
       " 'NOUN__Animacy=Anim|Case=Gen|Gender=Masc|Number=Sing',\n",
       " 'PUNCT___']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp_ = spacy.blank('ru')\n",
    "d, gp = next(g.train_docs(nlp_))\n",
    "gp.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(С. ГРИНФИЛД , директор Королевского института Великобритании . , <spacy.gold.GoldParse object at 0x7f1f3ccb9480>)\n"
     ]
    }
   ],
   "source": [
    "for i in g.train_docs(nlp_):\n",
    "    print(i)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'utils.corpus' from '/Projects/nlp/spacy/spacy-ru/utils/corpus.py'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from importlib import reload\n",
    "import utils.corpus\n",
    "reload(utils.corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.corpus import Corpus, tag_morphology, iter_corpora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "SynTagRus = Corpus.from_gold('ru', g)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(list(iter_corpora([SynTagRus]))) == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48814 6491\n",
      "733 608\n",
      "294 39\n",
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(len(SynTagRus.ds_train), len(SynTagRus.ds_test))\n",
    "print(len(SynTagRus.ds_train.pos), len(SynTagRus.ds_test.pos))\n",
    "print(len(SynTagRus.ds_train.dep), len(SynTagRus.ds_test.dep))\n",
    "print(len(SynTagRus.ds_train.ner), len(SynTagRus.ds_test.ner))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "USE_RU2 = False\n",
    "if USE_RU2:\n",
    "    import ru2e\n",
    "    nlp = ru2e.load_ru2('../../ru2e/')\n",
    "else:\n",
    "    nlp = spacy.blank('ru')\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.vocab.morphology.tag_map.clear()\n",
    "nlp.vocab.morphology.tag_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_submodel(nlp, name, rebuild=True):\n",
    "    if name in nlp.pipe_names and rebuild:\n",
    "        nlp.disable_pipes(name)\n",
    "    if name not in nlp.pipe_names:\n",
    "        print(\"Creating new submodel for {}...\".format(name))\n",
    "        submodel = nlp.create_pipe(name)\n",
    "        nlp.add_pipe(submodel)\n",
    "    submodel = nlp.get_pipe(name)\n",
    "    return submodel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new submodel for tagger...\n",
      "745\n",
      "Creating new submodel for parser...\n",
      "294\n",
      "Morphology tag map: 745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f1f39d28278>),\n",
       " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f1f38e309a8>)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def setup_ner(nlp, *corpora, rebuild=True):\n",
    "    ner = add_submodel(nlp, 'ner', rebuild=rebuild)\n",
    "    for c in iter_corpora(corpora):\n",
    "        for l in c.ents:\n",
    "            ner.add_label(l)\n",
    "\n",
    "def setup_tagger(nlp, *corpora, rebuild=True):\n",
    "    pos = add_submodel(nlp, 'tagger', rebuild=rebuild)\n",
    "    for c in iter_corpora(corpora):\n",
    "        for l in c.pos:\n",
    "            pos.add_label(l, tag_morphology(l))\n",
    "    print(len(pos.labels))\n",
    "\n",
    "def setup_parser(nlp, *corpora, rebuild=True):\n",
    "    dep = add_submodel(nlp, 'parser', rebuild=rebuild)\n",
    "    for c in iter_corpora(corpora):\n",
    "        for l in c.dep:\n",
    "            dep.add_label(l)\n",
    "    print(len(dep.labels))\n",
    "\n",
    "setup_tagger(nlp, SynTagRus, rebuild=True)\n",
    "setup_parser(nlp, SynTagRus, rebuild=True)\n",
    "#setup_ner(nlp, SynTagRus, rebuild=True)\n",
    "print(f\"Morphology tag map: {len(nlp.vocab.morphology.tag_map)}\")\n",
    "nlp.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TESTS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.pluck import pluck, pluck_list, pluck_dict\n",
    "from utils.tqdm import tqdm_batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import random\n",
    "from spacy.gold import GoldParse\n",
    "from spacy.scorer import Scorer\n",
    "import pandas\n",
    "pandas.set_option('display.precision', 3) \n",
    "\n",
    "def init_model(model, CFG):\n",
    "    for n, m in model.pipeline:\n",
    "        if m.model is True:\n",
    "            print(f\"Initializing model because of {n}!\")\n",
    "            model.begin_training(**CFG)\n",
    "            break\n",
    "\n",
    "def _evaluate(model, batches):\n",
    "    scorer = Scorer()\n",
    "    for batch in batches:\n",
    "        # print(\"Example batch:\", batch)\n",
    "        orig_docs, golds = zip(*batch)\n",
    "        docs = model.pipe([b.text for b in orig_docs])\n",
    "        for doc, parse in zip(docs, golds):\n",
    "            scorer.score(doc, parse)\n",
    "    return scorer.scores\n",
    "\n",
    "def evaluate(model, dataset, limit=None, batch_size=32):\n",
    "    generator = dataset.iter(model, limit=limit)\n",
    "    batches = tqdm_batches(minibatch(generator, batch_size), total=limit or len(dataset), leave=False)\n",
    "    return _evaluate(model, batches)\n",
    "\n",
    "def evaluate_data_source(model, ds, count=None, batch_size=32):\n",
    "    # enable_entities(model, ds.ds_test.ner)\n",
    "    res = evaluate(model, ds.ds_test, limit=count)\n",
    "    return res\n",
    "\n",
    "def get_ent_scores(res):\n",
    "    return {k:v for k,v in res['ents_per_type'].items() if k in ds.ents}\n",
    "\n",
    "def display_scores(list_of_scores):\n",
    "    if isinstance(list_of_scores, dict):\n",
    "        list_of_scores = [list_of_scores]\n",
    "    display(pandas.DataFrame.from_records(list_of_scores))\n",
    "\n",
    "def display_scores_t(list_of_scores):\n",
    "    if isinstance(list_of_scores, dict):\n",
    "        list_of_scores = [list_of_scores]\n",
    "    display(pandas.DataFrame.from_records(list_of_scores).T)\n",
    "\n",
    "if TESTS or 0:\n",
    "    init_model(nlp, CFG)\n",
    "    scores = evaluate_data_source(nlp, SynTagRus, count=None, batch_size=32)\n",
    "    display_scores(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "def get_other_pipes(nlp, *x):\n",
    "    return [pipe for pipe in nlp.pipe_names if pipe not in x]\n",
    "\n",
    "def _train_epoch(model, labels, batches):\n",
    "    init_model(model, CFG)\n",
    "    with model.disable_pipes(*get_other_pipes(model, 'tagger', 'parser')):\n",
    "        print(\"Training only:\", model.pipe_names)\n",
    "        optimizer = model.resume_training(**CFG)\n",
    "        losses = {}\n",
    "        n_docs = 0\n",
    "        for batch in batches:\n",
    "            texts, anns = zip(*batch)\n",
    "            # enable_entities(model, labels)\n",
    "            model.update(texts, anns, drop=0.2, losses=losses, sgd=optimizer)\n",
    "            n_docs += len(batch)\n",
    "        meta = {'loss_'+k: numpy.log(1e-10 + (v / n_docs)) for k,v in losses.items()}\n",
    "        meta['docs'] = n_docs\n",
    "    # enable_all_entities(model)\n",
    "    return meta\n",
    "\n",
    "def train_epoch(model, ds, batch_size, count=None):\n",
    "    batches = minibatch(ds.iter(model, limit=count), size=size_)\n",
    "    return _train_epoch(model, ds.ner, tqdm_batches(batches, total=count or len(ds)))\n",
    "\n",
    "if TESTS or 0:\n",
    "    size_ = compounding(1., 32., 1.001)\n",
    "    meta = train_epoch(nlp, SynTagRus.ds_train, batch_size=size_, count=1000)\n",
    "    display_scores(meta)\n",
    "\n",
    "if TESTS or 0:\n",
    "    display_scores(evaluate_data_source(nlp, SynTagRus))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTS or 0:\n",
    "    scorer = spacy.scorer.Scorer()\n",
    "    for doc, parse in tqdm(SynTagRus.ds_test.iter(nlp, limit=1000), total=1000):\n",
    "        doc = nlp(doc.text)\n",
    "        #explacy.print_parse_info(nlp, doc.text)\n",
    "        #parse.tags = [t.split('__', 1)[0] for t in parse.tags]\n",
    "        #print([(dt.tag_, pt) for dt,pt in zip(doc, parse.tags)])\n",
    "        scorer.score(doc, parse, verbose=False)\n",
    "    display_scores(scorer.scores)\n",
    "    #display_scores(evaluate_data_source(nlp, SynTagRus, count=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from notebooks.examples import explacy\n",
    "if TESTS or 0:\n",
    "    doc = nlp(u'Жизнь после двух тысяч первого года на Марсе стала сложней.')\n",
    "    explacy.print_parse_info(nlp, doc.text)\n",
    "    explacy.print_parse_info(nlp, d.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "CORPORA = [SynTagRus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69d32b0e8034445a91f14867a0b2674d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=60.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing model because of tagger!\n",
      "Training only: ['tagger', 'parser']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "332e5e3841564fc7a3979f7479db4f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=24407.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-98729133f737>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCORPORA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mds_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCORPORA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-0fbb4db10c50>\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(model, ds, batch_size, count)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mbatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mminibatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlimit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtqdm_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mTESTS\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-0fbb4db10c50>\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(model, labels, batches)\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m             \u001b[0;31m# enable_entities(model, labels)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mn_docs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'loss_'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1e-10\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mn_docs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Projects/nlp/spacy/spacy-ru/.venv/lib/python3.6/site-packages/spacy/language.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, docs, golds, drop, sgd, losses, component_cfg)\u001b[0m\n\u001b[1;32m    473\u001b[0m             \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcomponent_cfg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetdefault\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drop\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdrop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m             \u001b[0mproc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgolds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msgd\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mget_grads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlosses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgrads\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m                 \u001b[0msgd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnn_parser.pyx\u001b[0m in \u001b[0;36mspacy.syntax.nn_parser.Parser.update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserModel.begin_update.finish_parser_update\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.ParserStepModel.make_updates\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m_parser_model.pyx\u001b[0m in \u001b[0;36mspacy.syntax._parser_model.precompute_hiddens.begin_update.backward\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/Projects/nlp/spacy/spacy-ru/.venv/lib/python3.6/site-packages/spacy/_ml.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(dY_ids, sgd)\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0mWopfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m             \u001b[0mWopfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mascontiguousarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWopfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m             \u001b[0mWopfi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWopfi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnF\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnI\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m             \u001b[0mdXf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgemm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnO\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mWopfi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Projects/nlp/spacy/spacy-ru/.venv/lib/python3.6/site-packages/thinc/describe.py\u001b[0m in \u001b[0;36m__get__\u001b[0;34m(self, obj, type)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mDimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAttributeDescription\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__get__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dims\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "g.limit = None\n",
    "size_ = compounding(4., 32., 1.0005)\n",
    "for e in tqdm(range(60)):\n",
    "    res = {'epoch': e+1}\n",
    "    for c in CORPORA:\n",
    "        meta = train_epoch(nlp, c.ds_train, batch_size=size_, count=len(c.ds_train)//2)\n",
    "        res.update(meta)\n",
    "    for c in CORPORA:\n",
    "        res.update(evaluate_data_source(nlp, c, count=None))\n",
    "    display_scores(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import spacy.displacy\n",
    "def view_example(nlp, s):\n",
    "    print('Text:', s['raw'])\n",
    "    doc = nlp(s['raw'])\n",
    "#     print(\"Actual:\", [(e, e.label_) for e in doc.ents])\n",
    "    print(\"Expected:\", [(s['raw'][a:b],c,a,b) for a,b,c in s['entities']])\n",
    "    spacy.displacy.render(doc, style='ent')\n",
    "\n",
    "enable_all_entities(nlp)\n",
    "\n",
    "for s in NERUS.ds_test[:2]:\n",
    "    view_example(nlp, s)\n",
    "for s in KR.ds_test[:3]:\n",
    "    view_example(nlp, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to ../../ru2_pos_dep\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# save model to output directory\n",
    "def save_model(nlp, output_dir):\n",
    "    output_dir = Path(output_dir)\n",
    "    if not output_dir.exists():\n",
    "        output_dir.mkdir()\n",
    "    nlp.to_disk(output_dir)\n",
    "    print(\"Saved model to\", output_dir)\n",
    "save_model(nlp, '../../ru2_pos_dep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.tokenizer('приветы всем'.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.displacy.render(nlp('20 декабря 2019 года на улице Советской, город Новосибирск, мы с Сашей пошли гулять'), \n",
    "                      style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
